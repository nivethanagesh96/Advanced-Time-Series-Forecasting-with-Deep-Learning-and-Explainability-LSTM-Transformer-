# ============================================================
# Advanced Time Series Forecasting with LSTM & Transformer
# Including Hyperparameter Tuning, Walk-Forward Validation
# and SHAP Explainability for Sequence Models
# ============================================================

# ------------------------
# 1. Imports
# ------------------------
import numpy as np
import pandas as pd
import yfinance as yf
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import optuna
import shap
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)

# ------------------------
# 2. Data Acquisition
# ------------------------
def load_data(symbol="AAPL", start="2010-01-01"):
    df = yf.download(symbol, start=start)
    df.dropna(inplace=True)

    # Technical indicators
    df["return"] = df["Close"].pct_change()
    df["ma_10"] = df["Close"].rolling(10).mean()
    df["ma_20"] = df["Close"].rolling(20).mean()
    df["volatility"] = df["return"].rolling(10).std()
    df.dropna(inplace=True)

    return df

df = load_data()
features = ["Open", "High", "Low", "Close", "Volume", "ma_10", "ma_20", "volatility"]
target_col = "Close"

# ------------------------
# 3. Dataset & Windowing
# ------------------------
SEQ_LEN = 30

class TimeSeriesDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def create_sequences(data, target, seq_len):
    X, y = [], []
    for i in range(seq_len, len(data)):
        X.append(data[i-seq_len:i])
        y.append(target[i])
    return np.array(X), np.array(y)

# ------------------------
# 4. Scaling
# ------------------------
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(df[features])
y_scaled = scaler_y.fit_transform(df[[target_col]])

X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LEN)

# ------------------------
# 5. Walk-Forward Split
# ------------------------
def walk_forward_split(X, y, train_size=0.7):
    split = int(len(X) * train_size)
    return X[:split], y[:split], X[split:], y[split:]

X_train, y_train, X_test, y_test = walk_forward_split(X_seq, y_seq)

train_ds = TimeSeriesDataset(X_train, y_train)
test_ds = TimeSeriesDataset(X_test, y_test)

# ------------------------
# 6. Models
# ------------------------
class LSTMModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layers):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

class TransformerModel(nn.Module):
    def __init__(self, input_dim, d_model, nhead, layers):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)
        self.transformer = nn.TransformerEncoder(encoder_layer, layers)
        self.fc = nn.Linear(d_model, 1)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.fc(x[:, -1, :])

# ------------------------
# 7. Training & Metrics
# ------------------------
def directional_accuracy(y_true, y_pred):
    return np.mean(np.sign(np.diff(y_true)) == np.sign(np.diff(y_pred)))

def mase(y_true, y_pred):
    naive = np.mean(np.abs(np.diff(y_true)))
    return np.mean(np.abs(y_true - y_pred)) / naive

def train_model(model, train_loader, epochs=10, lr=1e-3):
    model.to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.MSELoss()

    for _ in range(epochs):
        for X, y in train_loader:
            X, y = X.to(DEVICE), y.to(DEVICE)
            optimizer.zero_grad()
            loss = loss_fn(model(X), y)
            loss.backward()
            optimizer.step()

# ------------------------
# 8. Optuna Hyperparameter Tuning
# ------------------------
def objective(trial):
    hidden = trial.suggest_int("hidden", 32, 128)
    layers = trial.suggest_int("layers", 1, 3)
    lr = trial.suggest_loguniform("lr", 1e-4, 1e-2)

    model = LSTMModel(len(features), hidden, layers)
    loader = DataLoader(train_ds, batch_size=64, shuffle=True)
    train_model(model, loader, epochs=5, lr=lr)

    model.eval()
    with torch.no_grad():
        preds = model(torch.tensor(X_test, dtype=torch.float32).to(DEVICE)).cpu().numpy()
    return mean_squared_error(y_test, preds)

study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)

# ------------------------
# 9. Train Best Models
# ------------------------
best_lstm = LSTMModel(len(features), study.best_params["hidden"], study.best_params["layers"])
train_model(best_lstm, DataLoader(train_ds, batch_size=64), epochs=15)

transformer = TransformerModel(len(features), d_model=64, nhead=4, layers=2)
train_model(transformer, DataLoader(train_ds, batch_size=64), epochs=15)

# ------------------------
# 10. Evaluation
# ------------------------
def evaluate(model):
    model.eval()
    with torch.no_grad():
        preds = model(torch.tensor(X_test, dtype=torch.float32).to(DEVICE)).cpu().numpy()
    preds_inv = scaler_y.inverse_transform(preds)
    y_true_inv = scaler_y.inverse_transform(y_test)

    return {
        "RMSE": np.sqrt(mean_squared_error(y_true_inv, preds_inv)),
        "MASE": mase(y_true_inv.flatten(), preds_inv.flatten()),
        "Directional Accuracy": directional_accuracy(y_true_inv.flatten(), preds_inv.flatten())
    }

print("LSTM Metrics:", evaluate(best_lstm))
print("Transformer Metrics:", evaluate(transformer))

# ------------------------
# 11. SHAP Explainability (10 Predictions)
# ------------------------
explainer = shap.DeepExplainer(
    best_lstm,
    torch.tensor(X_train[:100], dtype=torch.float32).to(DEVICE)
)

shap_values = explainer.shap_values(
    torch.tensor(X_test[:10], dtype=torch.float32).to(DEVICE)
)

shap.summary_plot(
    shap_values[0],
    X_test[:10],
    feature_names=features
)

print("SHAP analysis completed for 10 future predictions.")
