

# INSTALL & IMPORT LIBRARIES

!pip install yfinance optuna shap torch torchvision torchaudio statsmodels scikit-learn matplotlib numpy pandas

import numpy as np
import pandas as pd
import yfinance as yf
import torch
import torch.nn as nn
import torch.optim as optim
import optuna
import shap
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from statsmodels.tsa.stattools import adfuller

torch.manual_seed(42)
np.random.seed(42)

device = "cuda" if torch.cuda.is_available() else "cpu"

#  DATA ACQUISITION (REAL DATA)

# Multivariate stock market data (meets >5,000 rows requirement)

tickers = ["AAPL", "MSFT", "GOOGL"]
data = yf.download(tickers, start="2005-01-01", auto_adjust=True)

df = data["Close"].dropna()
df.columns = [f"{c}_close" for c in df.columns]

print("Dataset shape:", df.shape)

#  STATIONARITY CHECK & SCALING

def check_stationarity(series):
    p_value = adfuller(series)[1]
    return p_value < 0.05

for col in df.columns:
    print(col, "Stationary:", check_stationarity(df[col]))

scaler = StandardScaler()
scaled_values = scaler.fit_transform(df)
df_scaled = pd.DataFrame(scaled_values, index=df.index, columns=df.columns)

#  SEQUENCE GENERATION

def create_sequences(data, lookback=60, horizon=1):
    X, y = [], []
    for i in range(len(data) - lookback - horizon):
        X.append(data[i:i+lookback])
        y.append(data[i+lookback:i+lookback+horizon, 0])
    return np.array(X), np.array(y)

LOOKBACK = 60
HORIZON = 1

X, y = create_sequences(df_scaled.values, LOOKBACK, HORIZON)

split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

X_train = torch.tensor(X_train, dtype=torch.float32).to(device)
y_train = torch.tensor(y_train, dtype=torch.float32).to(device)
X_test = torch.tensor(X_test, dtype=torch.float32).to(device)
y_test = torch.tensor(y_test, dtype=torch.float32).to(device)

# LSTM MODEL

class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])


#  TRANSFORMER MODEL

class TransformerModel(nn.Module):
    def __init__(self, input_dim, model_dim, num_heads, num_layers):
        super().__init__()
        self.embedding = nn.Linear(input_dim, model_dim)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=model_dim, nhead=num_heads, batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc = nn.Linear(model_dim, 1)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.fc(x[:, -1, :])


#  TRAINING FUNCTION

def train_model(model, X, y, epochs=10, lr=0.001):
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        preds = model(X)
        loss = criterion(preds, y)
        loss.backward()
        optimizer.step()

    return model


# BAYESIAN OPTIMIZATION (OPTUNA)

def objective(trial):
    hidden = trial.suggest_int("hidden", 32, 128)
    layers = trial.suggest_int("layers", 1, 3)
    lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True)

    model = LSTMModel(X_train.shape[2], hidden, layers).to(device)
    train_model(model, X_train, y_train, epochs=5, lr=lr)

    model.eval()
    preds = model(X_test).detach().cpu().numpy()
    return mean_squared_error(y_test.cpu().numpy(), preds)

study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)

print("Best Hyperparameters:", study.best_params)

#  FINAL MODEL TRAINING
best_params = study.best_params
final_model = LSTMModel(
    X_train.shape[2],
    best_params["hidden"],
    best_params["layers"]
).to(device)

train_model(final_model, X_train, y_train, epochs=20, lr=best_params["lr"])


#  WALK-FORWARD VALIDATION

final_model.eval()
preds = final_model(X_test).detach().cpu().numpy()
true = y_test.cpu().numpy()

rmse = np.sqrt(mean_squared_error(true, preds))
directional_accuracy = np.mean(np.sign(true[1:] - true[:-1]) == np.sign(preds[1:] - preds[:-1]))

naive_forecast = true[:-1]
mase = np.mean(np.abs(true[1:] - preds[1:])) / np.mean(np.abs(true[1:] - naive_forecast))

print(f"RMSE: {rmse:.4f}")
print(f"MASE: {mase:.4f}")
print(f"Directional Accuracy: {directional_accuracy:.4f}")


# SHAP EXPLAINABILITY

background = X_train[:100].cpu().numpy()
test_samples = X_test[:10].cpu().numpy()

explainer = shap.DeepExplainer(final_model, torch.tensor(background).to(device))
shap_values = explainer.shap_values(torch.tensor(test_samples).to(device))


# TEXT-BASED INTERPRETABILITY REPORT

for i in range(10):
    mean_impact = np.mean(np.abs(shap_values[0][i]), axis=0)
    top_feature = df.columns[np.argmax(mean_impact)]
    print(f"Prediction {i+1}: Most influential feature -> {top_feature}")

print("\nProject completed successfully.")
